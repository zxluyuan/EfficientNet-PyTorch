"""
åŸºäºtimmåº“çš„ConvNeXt-Tinyå¿«é€Ÿé›†æˆè®­ç»ƒè„šæœ¬
å®Œå…¨å¯¹é½Enhanced_train_0.pyçš„é…ç½®å’ŒæŒ‡æ ‡è¾“å‡º
"""

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision.datasets import ImageFolder
import torchvision.transforms as transforms
import pandas as pd
import numpy as np
import sklearn.metrics as metrics
from tqdm import tqdm

# å¯¼å…¥timmåº“
try:
    import timm
    TIMM_AVAILABLE = True
    print("âœ“ æˆåŠŸå¯¼å…¥timmåº“")
except ImportError:
    TIMM_AVAILABLE = False
    print("âœ— æœªæ‰¾åˆ°timmåº“ï¼Œè¯·å…ˆå®‰è£…: pip install timm")

def get_data_loaders(data_path, batch_size=16):
    """æ•°æ®åŠ è½½å™¨ - ä¸Enhanced_train_0.pyå®Œå…¨å¯¹é½"""
    # å•é€šé“å›¾åƒé¢„å¤„ç†ï¼ˆé€‚ç”¨äºRPå›¾åƒç­‰ç°åº¦å›¾ï¼‰
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.Grayscale(num_output_channels=1),  # è½¬æ¢ä¸ºå•é€šé“
        transforms.ToTensor(),
        # å•é€šé“æ ‡å‡†åŒ–
        transforms.Normalize(mean=[0.449], std=[0.227])
    ])
    
    train_dataset = ImageFolder(os.path.join(data_path, 'train'), transform=transform)
    val_dataset = ImageFolder(os.path.join(data_path, 'val'), transform=transform)
    
    return train_dataset, val_dataset
    
    # å®Œå…¨å¯¹é½çš„DataLoaderé…ç½®
    train_loader = DataLoader(
        train_dataset, 
        batch_size=batch_size, 
        shuffle=True, 
        num_workers=0  # ä¸è¦æ±‚ä¸€è‡´
    )
    
    val_loader = DataLoader(
        val_dataset, 
        batch_size=batch_size, 
        shuffle=False,  # ä¸è¦æ±‚ä¸€è‡´
        num_workers=0   # ä¸è¦æ±‚ä¸€è‡´
    )
    
    return train_loader, val_loader, len(train_dataset.classes)

def create_convnext_model(num_classes=6):
    """åˆ›å»ºConvNeXt-Tinyæ¨¡å‹ - ä»å¤´è®­ç»ƒï¼ˆå•é€šé“è¾“å…¥ï¼‰"""
    if not TIMM_AVAILABLE:
        raise RuntimeError("timmåº“ä¸å¯ç”¨ï¼Œè¯·å…ˆå®‰è£…: pip install timm")
    
    # ä»å¤´è®­ç»ƒConvNeXt-Tinyï¼ˆæ— é¢„è®­ç»ƒæƒé‡ï¼‰
    model = timm.create_model(
        'convnext_tiny',
        pretrained=False,        # ä¸ä½¿ç”¨é¢„è®­ç»ƒæƒé‡
        num_classes=num_classes, # ä½ çš„ç±»åˆ«æ•°
        in_chans=1              # å•é€šé“è¾“å…¥
    )
    
    return model

def train_epoch(model, loader, criterion, optimizer, device, epoch_desc=""):
    """è®­ç»ƒä¸€ä¸ªepoch - ä¸Enhanced_train_0.pyå¯¹é½"""
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0
    
    with tqdm(total=len(loader), desc=epoch_desc, unit='batch') as pbar:
        for images, labels in loader:
            images, labels = images.to(device), labels.to(device)
            
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            
            running_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()
            
            pbar.set_postfix({
                'loss': running_loss / (pbar.n + 1),
                'acc': 100.*correct/total
            })
            pbar.update(1)
    
    return running_loss / len(loader), 100. * correct / total

def evaluate(model, loader, criterion, device):
    """è¯„ä¼°æ¨¡å‹ - ä¸Enhanced_train_0.pyå¯¹é½"""
    model.eval()
    total_loss = 0.0
    correct = 0
    total = 0
    all_preds = []
    all_labels = []
    
    with torch.no_grad():
        for images, labels in loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            
            total_loss += loss.item()
            _, predicted = outputs.max(1)
            
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()
            
            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
    
    accuracy = 100. * correct / total
    avg_loss = total_loss / len(loader)
    
    return avg_loss, accuracy, all_preds, all_labels

def save_training_metrics(train_losses, val_losses, train_accs, val_accs, cm, output_dir='/kaggle/working/'):
    """ä¿å­˜è®­ç»ƒæŒ‡æ ‡ - ä¸Enhanced_train_0.pyå®Œå…¨å¯¹é½"""
    # ä¿å­˜CSVæŒ‡æ ‡æ–‡ä»¶ï¼ˆæ ¼å¼å®Œå…¨ä¸€è‡´ï¼‰
    metrics_df = pd.DataFrame({
        'Epoch': range(1, len(train_losses) + 1),
        'Train Loss': train_losses,
        'Val Loss': val_losses, 
        'Train Accuracy': [acc/100.0 for acc in train_accs],  # è½¬æ¢ä¸ºå°æ•°
        'Val Accuracy': [acc/100.0 for acc in val_accs]      # è½¬æ¢ä¸ºå°æ•°
    })
    
    csv_path = os.path.join(output_dir, 'convnext_timm_metrics.csv')
    metrics_df.to_csv(csv_path, index=False)
    print(f"âœ“ è®­ç»ƒæŒ‡æ ‡å·²ä¿å­˜åˆ°: {csv_path}")
    
    # ä¿å­˜æ··æ·†çŸ©é˜µï¼ˆæ ¼å¼å®Œå…¨ä¸€è‡´ï¼‰
    cm_path = os.path.join(output_dir, 'convnext_timm_confusion_matrix.txt')
    np.savetxt(cm_path, cm, fmt='%d')
    print(f"âœ“ æ··æ·†çŸ©é˜µå·²ä¿å­˜åˆ°: {cm_path}")

def main():
    """ä¸»è®­ç»ƒå‡½æ•° - å®Œå…¨å¯¹é½Enhanced_train_0.py"""
    # é…ç½®å‚æ•°ï¼ˆä¸Enhanced_train_0.pyå®Œå…¨ä¸€è‡´ï¼‰
    config = {
        'data_path': '/kaggle/input/your-dataset/data',
        'num_classes': 6,
        'epochs': 50,           # ç›¸åŒè®­ç»ƒè½®æ•°
        'batch_size': 16,
        'learning_rate': 0.0005, # ç›¸åŒå­¦ä¹ ç‡
        'device': 'cuda' if torch.cuda.is_available() else 'cpu'
    }
    
    print("=" * 50)
    print("ğŸš€ åŸºäºtimmçš„ConvNeXt-Tinyä»å¤´è®­ç»ƒå¯åŠ¨")
    print("=" * 50)
    print("ğŸ¯ è®­ç»ƒæ¨¡å¼: å•é€šé“è¾“å…¥ | æ— é¢„è®­ç»ƒæƒé‡ | éšæœºåˆå§‹åŒ–")
    print(f"ä½¿ç”¨è®¾å¤‡: {config['device']}")
    print(f"æ•°æ®è·¯å¾„: {config['data_path']}")
    print(f"ç±»åˆ«æ•°é‡: {config['num_classes']}")
    print(f"è®­ç»ƒè½®æ•°: {config['epochs']}")
    print(f"æ‰¹å¤„ç†å¤§å°: {config['batch_size']}")
    print(f"å­¦ä¹ ç‡: {config['learning_rate']}")
    
    # è®¾ç½®éšæœºç§å­ç¡®ä¿å¯é‡ç°æ€§
    torch.manual_seed(42)
    np.random.seed(42)
    
    # æ•°æ®åŠ è½½ï¼ˆå®Œå…¨å¯¹é½é…ç½®ï¼‰
    print("\nğŸ“‚ åŠ è½½æ•°æ®é›†...")
    train_dataset, val_dataset = get_data_loaders(
        config['data_path'], 
        config['batch_size']
    )
    
    # åˆ›å»ºDataLoader
    train_loader = DataLoader(
        train_dataset, 
        batch_size=config['batch_size'], 
        shuffle=True, 
        num_workers=0
    )
    
    val_loader = DataLoader(
        val_dataset, 
        batch_size=config['batch_size'], 
        shuffle=False, 
        num_workers=0
    )
    
    print(f"âœ“ è®­ç»ƒé›†æ ·æœ¬æ•°: {len(train_dataset)}")
    print(f"âœ“ éªŒè¯é›†æ ·æœ¬æ•°: {len(val_dataset)}")
    print(f"âœ“ ç±»åˆ«æ•°é‡: {len(train_dataset.classes)}")
    print(f"âœ“ è®­ç»ƒé›†ç±»åˆ«åˆ†å¸ƒ: {dict(zip(train_dataset.classes, np.bincount([y for _, y in train_dataset])))}")
    
    # æ¨¡å‹åˆå§‹åŒ–ï¼ˆä½¿ç”¨timmï¼‰
    print("\nğŸ§  åˆå§‹åŒ–ConvNeXt-Tinyæ¨¡å‹...")
    model = create_convnext_model(num_classes=len(train_dataset.classes))
    model = model.to(config['device'])
    print(f"âœ“ æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    
    # æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨ï¼ˆä¸Enhanced_train_0.pyå®Œå…¨å¯¹é½ï¼‰
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])
    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)
    
    # è®­ç»ƒå¾ªç¯
    train_losses, val_losses = [], []
    train_accuracies, val_accuracies = [], []
    best_val_acc = 0.0
    
    print(f"\nğŸƒ å¼€å§‹è®­ç»ƒ ({config['epochs']} epochs)...")
    print("=" * 50)
    
    for epoch in range(config['epochs']):
        # è®­ç»ƒé˜¶æ®µ
        train_loss, train_acc = train_epoch(
            model, train_loader, criterion, optimizer, config['device'],
            f'Epoch {epoch+1}/{config["epochs"]}'
        )
        
        # éªŒè¯é˜¶æ®µ
        val_loss, val_acc, val_preds, val_labels = evaluate(
            model, val_loader, criterion, config['device']
        )
        
        # è®°å½•æŒ‡æ ‡
        train_losses.append(train_loss)
        val_losses.append(val_loss)
        train_accuracies.append(train_acc)
        val_accuracies.append(val_acc)
        
        # å­¦ä¹ ç‡è°ƒåº¦
        scheduler.step()
        
        # æ‰“å°ç»“æœ
        current_lr = scheduler.get_last_lr()[0]
        print(f'Epoch [{epoch+1:2d}/{config["epochs"]}] - '
              f'LR: {current_lr:.6f} - '
              f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% - '
              f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')
        
        # æ·»åŠ é¢„è­¦ä¿¡æ¯
        if epoch >= 2 and train_acc < 25:
            print("âš ï¸  è­¦å‘Š: è®­ç»ƒå‡†ç¡®ç‡è¿‡ä½ï¼Œå¯èƒ½å­˜åœ¨ä»¥ä¸‹é—®é¢˜:")
            print("   1. æ•°æ®æ ‡ç­¾å¯èƒ½ä¸æ­£ç¡®")
            print("   2. å­¦ä¹ ç‡å¯èƒ½è¿‡ä½")
            print("   3. æ•°æ®é¢„å¤„ç†å¯èƒ½æœ‰é—®é¢˜")
            print("   4. æ¨¡å‹åˆå§‹åŒ–å¯èƒ½æœ‰é—®é¢˜")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            best_model_path = '/kaggle/working/best_convnext_timm_model.pth'
            torch.save(model.state_dict(), best_model_path)
            print(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ (acc: {best_val_acc:.2f}%)")
    
    # ç”Ÿæˆæœ€ç»ˆè¯„ä¼°ç»“æœ
    print("\n" + "=" * 50)
    print("ğŸ“ˆ è®­ç»ƒå®Œæˆ - ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š")
    print("=" * 50)
    
    final_val_loss, final_val_acc, final_preds, final_labels = evaluate(
        model, val_loader, criterion, config['device']
    )
    
    # ç”Ÿæˆæ··æ·†çŸ©é˜µ
    cm = metrics.confusion_matrix(final_labels, final_preds)
    
    # ä¿å­˜æ‰€æœ‰ç»“æœ
    save_training_metrics(
        train_losses, val_losses, train_accuracies, val_accuracies, cm
    )
    
    # æœ€ç»ˆç»Ÿè®¡
    print(f"\nğŸ¯ è®­ç»ƒæ€»ç»“:")
    print(f"   æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%")
    print(f"   æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡: {final_val_acc:.2f}%")
    print(f"   æ€»è®­ç»ƒè½®æ•°: {config['epochs']}")
    print(f"   æ¨¡å‹ä¿å­˜è·¯å¾„: /kaggle/working/best_convnext_timm_model.pth")
    print(f"   æŒ‡æ ‡æ–‡ä»¶è·¯å¾„: /kaggle/working/convnext_timm_metrics.csv")
    print(f"   æ··æ·†çŸ©é˜µè·¯å¾„: /kaggle/working/convnext_timm_confusion_matrix.txt")
    print("=" * 50)

if __name__ == '__main__':
    # Kaggleç¯å¢ƒæ£€æµ‹
    if 'KAGGLE_CONTAINER_NAME' in os.environ or 'IN_KAGGLE' in os.environ:
        print("ğŸ” æ£€æµ‹åˆ°Kaggleç¯å¢ƒ")
        os.environ['IN_KAGGLE'] = '1'
    
    # è¿è¡Œä¸»å‡½æ•°
    main()