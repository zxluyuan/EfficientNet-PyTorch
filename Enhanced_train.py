import os
# ğŸ”§ æå‰è®¾ç½®ç¯å¢ƒå˜é‡ç¡®ä¿CUDAç¡®å®šæ€§
os.environ['PYTHONHASHSEED'] = '42'
os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'  # CUDA >= 10.2ç¡®å®šæ€§

import argparse
import torch
import torch.nn as nn
import torch.optim as optim
# transformsæ¨¡å—å·²ç§»é™¤ï¼Œä½¿ç”¨é»˜è®¤æ•°æ®åŠ è½½
from torch.utils.data import DataLoader
from torchvision.datasets import ImageFolder
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import sklearn.metrics as metrics
import seaborn as sns
import sys
sys.path.insert(0, '/kaggle/input/efficient-1/EfficientNet-PyTorch-MLOps')

# ä½¿ç”¨æ ‡å‡†äº¤å‰ç†µæŸå¤±å‡½æ•°
ARC_FACE_AVAILABLE = False
print("âœ“ ä½¿ç”¨æ ‡å‡†äº¤å‰ç†µæŸå¤±å‡½æ•°")

# æ­£ç¡®å¯¼å…¥EfficientNet
try:
    # å°è¯•å¤šç§å¯¼å…¥æ–¹å¼
    try:
        from efficientnet_pytorch import EfficientNet
        print("âœ“ ä» efficientnet_pytorch å¯¼å…¥æˆåŠŸ")
    except ImportError:
        try:
            from efficientnet_pytorch.model import EfficientNet
            print("âœ“ ä» efficientnet_pytorch.model å¯¼å…¥æˆåŠŸ")
        except ImportError:
            # æœ€åå°è¯•ç›¸å¯¹å¯¼å…¥
            import efficientnet_pytorch.model
            EfficientNet = efficientnet_pytorch.model.EfficientNet
            print("âœ“ é€šè¿‡æ¨¡å—å±æ€§è®¿é—®å¯¼å…¥æˆåŠŸ")
except Exception as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·æ£€æŸ¥ efficientnet_pytorch æ¨¡å—æ˜¯å¦æ­£ç¡®å®‰è£…")
    raise


def load_efficientnet_with_attention(model_name='efficientnet-b0', num_classes=1000, num_heads=8, reduction=8):
    """
    åˆå§‹åŒ–EfficientNet-B0éšæœºæƒé‡ï¼Œæ³¨æ„åŠ›æ¨¡å—ä½¿ç”¨éšæœºåˆå§‹åŒ–
    
    Args:
        model_name (str): æ¨¡å‹åç§°
        num_classes (int): åˆ†ç±»æ•°é‡
        num_heads (int): æ³¨æ„åŠ›å¤´æ•°é‡
    
    Returns:
        model: é…ç½®å¥½çš„å¸¦æ³¨æ„åŠ›çš„æ¨¡å‹
    """
    print("æ­£åœ¨åˆå§‹åŒ–EfficientNet-B0éšæœºæƒé‡æ¨¡å‹...")
    
    # ç›´æ¥åˆ›å»ºå¸¦æ³¨æ„åŠ›çš„æ¨¡å‹ï¼ˆä½¿ç”¨éšæœºåˆå§‹åŒ–ï¼‰
    print("æ­£åœ¨åˆå§‹åŒ–å¸¦RPæ„ŸçŸ¥æ³¨æ„åŠ›çš„æ¨¡å‹...")
    model = EfficientNetWithAttention(model_name=model_name, num_classes=num_classes, num_heads=num_heads, reduction=reduction)
    
    # éªŒè¯æ¨¡å‹å‚æ•°çŠ¶æ€
    total_params = sum(p.numel() for p in model.parameters())
    attention_params = sum(p.numel() for p in model.attention.parameters())
    backbone_params = total_params - attention_params
    
    print(f"âœ“ æ¨¡å‹åˆå§‹åŒ–å®Œæˆ:")
    print(f"  - ä¸»å¹²ç½‘ç»œå‚æ•°: {backbone_params:,} (éšæœºåˆå§‹åŒ–)")
    print(f"  - æ³¨æ„åŠ›æ¨¡å—å‚æ•°: {attention_params:,} (éšæœºåˆå§‹åŒ–)")
    print(f"  - æ€»å‚æ•°é‡: {total_params:,}")
    
    return model


from tqdm import tqdm


class RPAwareAttentionLayer(nn.Module):
    """
    Args:
        in_channels (int): è¾“å…¥é€šé“æ•°
        num_heads (int): æ³¨æ„åŠ›å¤´æ•°é‡

    """
    def __init__(self, in_channels):
        super(RPAwareAttentionLayer, self).__init__()
        
        hidden_dim = in_channels // 10
        
        # ä½¿ç”¨ 1Ã—1 å·ç§¯è¿›è¡Œé€šé“æ³¨æ„åŠ›
        self.conv1 = nn.Conv2d(in_channels, hidden_dim, kernel_size=1, bias=False)
        self.conv2 = nn.Conv2d(hidden_dim, in_channels, kernel_size=1, bias=False)
        self.relu = nn.ReLU()

    def forward(self, x):
        # ç”Ÿæˆæ–¹å‘æ•æ„Ÿçš„æ³¨æ„åŠ›æƒé‡
        attention_weights = torch.sigmoid(self.conv2(self.relu(self.conv1(x))))
        return x * attention_weights


class EfficientNetWithAttention(nn.Module):
    def __init__(self, model_name='efficientnet-b0', num_classes=1000, num_heads=8):
        super(EfficientNetWithAttention, self).__init__()
        self.efficientnet = EfficientNet.from_pretrained(model_name, num_classes=num_classes)
        self.attention = RPAwareAttentionLayer(in_channels=1280)

    def forward(self, x):
        x = self.efficientnet.extract_features(x)
        x = self.attention(x)
        x = self.efficientnet._avg_pooling(x)
        x = x.flatten(start_dim=1)
        x = self.efficientnet._dropout(x)
        x = self.efficientnet._fc(x)
        return x

    def extract_features(self, x):
        return self.efficientnet.extract_features(x)


# è¯„ä¼°æ¨¡å‹å‡½æ•°
# æ¨¡å‹è®­ç»ƒ
def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, device, epochs, num_classes):
    train_losses, val_losses = [], []
    train_accuracies, val_accuracies = [], []
    cm = np.zeros((num_classes, num_classes))  # åˆå§‹åŒ–æ··æ·†çŸ©é˜µ

    for epoch in range(epochs):
        model.train()
        running_loss = 0.0

        with tqdm(total=len(train_loader), desc=f'Epoch {epoch + 1}/{epochs}', unit='batch') as pbar:
            for images, labels in train_loader:
                images, labels = images.to(device), labels.to(device)
                optimizer.zero_grad()
                outputs = model(images)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()
                running_loss += loss.item()
                pbar.set_postfix(loss=running_loss / (pbar.n + 1))
                pbar.update(1)

        train_loss = running_loss / len(train_loader)
        train_losses.append(train_loss)

        # è¯„ä¼°è®­ç»ƒé›†å’ŒéªŒè¯é›†
        val_loss, val_accuracy, val_preds, val_labels = evaluate_model(model, val_loader, criterion, device)
        train_accuracy = evaluate_model(model, train_loader, criterion, device)[1]  # è·å–è®­ç»ƒå‡†ç¡®ç‡
        val_losses.append(val_loss)
        train_accuracies.append(train_accuracy)
        val_accuracies.append(val_accuracy)

        # # æ›´æ–°æ··æ·†çŸ©é˜µ
        # _, preds = torch.max(outputs, 1)
        # for true, pred in zip(labels.cpu().numpy(), preds.cpu().numpy()):
        #     cm[true, pred] += 1
        # æ›´æ–°æ··æ·†çŸ©é˜µï¼ˆä»…åœ¨éªŒè¯é›†ä¸Šï¼‰
        for true, pred in zip(val_labels, val_preds):
            cm[true, pred] += 1

        print(f'Epoch [{epoch + 1}/{epochs}], '
              f'Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}, '
              f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')

        scheduler.step()

    # ä¿å­˜æŒ‡æ ‡å’Œæ··æ·†çŸ©é˜µ
    save_metrics(train_losses, val_losses, train_accuracies, val_accuracies, cm)

    return train_losses, val_losses, train_accuracies, val_accuracies


def evaluate_model(model, loader, criterion, device):
    model.eval()
    total_loss = 0.0
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for images, labels in loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            total_loss += loss.item()
            _, preds = torch.max(outputs, 1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    avg_loss = total_loss / len(loader)
    accuracy = np.mean(np.array(all_preds) == np.array(all_labels))
    return avg_loss, accuracy, all_preds, all_labels  # è¿”å›æŸå¤±ã€å‡†ç¡®ç‡ã€é¢„æµ‹å’ŒçœŸå®æ ‡ç­¾


# æ•°æ®ä¿å­˜
def save_metrics(train_losses, val_losses, train_accuracies, val_accuracies, cm, filename_prefix='metrics'):
    # ä¿å­˜æŸå¤±å’Œå‡†ç¡®ç‡åˆ° CSV æ–‡ä»¶
    metrics_df = pd.DataFrame({
        'Epoch': range(1, len(train_losses) + 1),
        'Train Loss': train_losses,
        'Val Loss': val_losses,
        'Train Accuracy': train_accuracies,
        'Val Accuracy': val_accuracies
    })
    metrics_df.to_csv(f'/kaggle/working/{filename_prefix}_metrics.csv', index=False)
    print(f'Metrics saved to /kaggle/working/{filename_prefix}_metrics.csv')

    # ä¿å­˜æ··æ·†çŸ©é˜µåˆ° TXT æ–‡ä»¶
    np.savetxt(f'/kaggle/working/{filename_prefix}_confusion_matrix.txt', cm, fmt='%d')
    print(f'Confusion matrix saved to /kaggle/working/{filename_prefix}_confusion_matrix.txt')


# ç»˜åˆ¶æŸå¤±å’Œå‡†ç¡®ç‡çš„å‡½æ•°
def plot_metrics(train_losses, val_losses, train_accuracies, val_accuracies, epochs):
    # ç»˜åˆ¶æŸå¤±æ›²çº¿
    plt.figure(figsize=(10, 6))
    plt.plot(range(1, epochs + 1), train_losses, label='Training Loss', color='blue')
    plt.plot(range(1, epochs + 1), val_losses, label='Validation Loss', color='red')
    plt.title('Training and Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.ylim(0, 1)
    plt.xticks(range(0, epochs + 1, 10))  # xè½´åˆ»åº¦ä¸º0, 10, 20, ...
    plt.yticks(np.arange(0, 1.1, 0.2))  # yè½´åˆ»åº¦ä¸º0.0, 0.2, 0.4, ..., 1.0
    plt.legend()
    plt.grid(False)
    plt.show()

    # ç»˜åˆ¶å‡†ç¡®ç‡æ›²çº¿
    plt.figure(figsize=(10, 6))
    plt.plot(range(1, epochs + 1), train_accuracies, label='Training Accuracy', color='blue')
    plt.plot(range(1, epochs + 1), val_accuracies, label='Validation Accuracy', color='red')
    plt.title('Training and Validation Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.ylim(0, 1)
    plt.xticks(range(0, epochs + 1, 10))  # xè½´åˆ»åº¦ä¸º0, 10, 20, ...
    plt.yticks(np.arange(0, 1.1, 0.2))  # yè½´åˆ»åº¦ä¸º0.0, 0.2, 0.4, ..., 1.0
    plt.legend()
    plt.grid(False)
    plt.show()


# ç»˜åˆ¶æ··æ·†çŸ©é˜µçš„å‡½æ•°
def plot_confusion_matrix(cm, class_names):
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=class_names, yticklabels=class_names)
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.title('Confusion Matrix')
    plt.show()


# æå–ç‰¹å¾å‘é‡çš„å‡½æ•°
def extract_features(model, loader, device):
    model.eval()  # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
    all_features = []
    all_labels = []

    with torch.no_grad():  # ç¦ç”¨æ¢¯åº¦è®¡ç®—
        for images, labels in loader:
            images = images.to(device)

            # æå–ä¸­é—´å±‚è¾“å‡ºï¼ˆç‰¹å¾å‘é‡ï¼‰
            features = model.extract_features(images)
            features = features.view(features.size(0), -1)  # å°†ç‰¹å¾å‘é‡å±•å¹³ä¸ºäºŒç»´

            all_features.extend(features.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    return np.array(all_features), np.array(all_labels)


# ä¿å­˜ç‰¹å¾å‘é‡åˆ°æ–‡ä»¶
def save_features(features, labels, filename='val_features.npy'):
    np.save(f'/kaggle/working/{filename}', {'features': features, 'labels': labels})
    print(f"Features saved to /kaggle/working/{filename}")


def main(args, num_classes):
    print(f"Using device: {args.device}")
    
    # ğŸ”§ è®¾ç½®ç¡®å®šæ€§è®­ç»ƒç¯å¢ƒ
    torch.manual_seed(42)
    torch.cuda.manual_seed(42)
    torch.cuda.manual_seed_all(42)
    np.random.seed(42)
    import random
    random.seed(42)
    
    # è®¾ç½®CUDAç¡®å®šæ€§
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    torch.use_deterministic_algorithms(True, warn_only=True)  # PyTorch 1.8+
    
    print("âœ“ ç¡®å®šæ€§ç¯å¢ƒå·²è®¾ç½® (seed=42)")

    # ç›´æ¥ä½¿ç”¨é»˜è®¤å˜æ¢
    train_dataset = ImageFolder(os.path.join(args.data, 'train'))
    val_dataset = ImageFolder(os.path.join(args.data, 'val'))

    # ä½¿ç”¨é»˜è®¤DataLoaderé…ç½®
    
    train_loader = DataLoader(
        train_dataset, 
        batch_size=args.batch_size, 
        shuffle=True, 
        num_workers=args.workers
    )
    val_loader = DataLoader(
        val_dataset, 
        batch_size=args.batch_size, 
        shuffle=False, 
        num_workers=args.workers
    )

    # ä½¿ç”¨åˆå¹¶åçš„å¯é åŠ è½½æ–¹å¼
    model = load_efficientnet_with_attention(
        model_name='efficientnet-b0', 
        num_classes=num_classes, 
        num_heads=args.num_heads,
        reduction=args.reduction
    )
    print("âœ“ æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨éšæœºæƒé‡")
    
    model = model.to(args.device)

    # é…ç½®æŸå¤±å‡½æ•°
    criterion = nn.CrossEntropyLoss()
    print("âœ“ ä½¿ç”¨æ ‡å‡†äº¤å‰ç†µæŸå¤±")
    
    optimizer = optim.Adam(model.parameters(), lr=args.lr)
    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)

    # å°†num_classesä¼ é€’ç»™train_modelå‡½æ•°
    train_losses, val_losses, train_accuracies, val_accuracies = train_model(
        model, train_loader, val_loader, 
        criterion, optimizer, scheduler, args.device, args.epochs, num_classes
    )

    # ç»˜åˆ¶è®­ç»ƒå’ŒéªŒè¯æŸå¤±åŠå‡†ç¡®ç‡
    plot_metrics(train_losses, val_losses, train_accuracies, val_accuracies, args.epochs)

    # æå–éªŒè¯é›†ç‰¹å¾
    val_features, val_labels = extract_features(model, val_loader, args.device)
    save_features(val_features, val_labels, filename='val_features.npy')

    # è¯„ä¼°æ¨¡å‹å¹¶ç»˜åˆ¶æ··æ·†çŸ©é˜µ
    val_loss, val_accuracy, val_preds, val_labels = evaluate_model(model, val_loader, criterion, args.device)
    cm = metrics.confusion_matrix(val_labels, val_preds)

    # ä¿å­˜æŒ‡æ ‡å’Œæ··æ·†çŸ©é˜µ
    save_metrics(train_losses, val_losses, train_accuracies, val_accuracies, cm)

    # ç»˜åˆ¶æ··æ·†çŸ©é˜µ
    plot_confusion_matrix(cm, class_names=[str(i) for i in range(len(val_dataset.classes))])


def get_default_args():
    """è·å–é»˜è®¤è®­ç»ƒå‚æ•°"""
    class Args:
        def __init__(self):
            self.data = '/kaggle/input/your-dataset/data'
            self.epochs = 50
            self.batch_size = 16
            self.lr = 0.0005
            self.workers = 4
            self.image_size = 224
            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
            self.num_heads = 8
            self.reduction = 10  # RPæ„ŸçŸ¥é—¨æ§çš„é€šé“ç¼©å‡æ¯”ä¾‹
    return Args()

if __name__ == '__main__':
    # Jupyter/Colabå…¼å®¹æ€§å¤„ç†
    import sys
    
    # æ£€æŸ¥æ˜¯å¦åœ¨Jupyterç¯å¢ƒä¸­
    if 'ipykernel' in sys.modules or 'colab' in sys.modules:
        print("æ£€æµ‹åˆ°Jupyter/Colabç¯å¢ƒï¼Œä½¿ç”¨é»˜è®¤å‚æ•°...")
        args = get_default_args()
        num_classes = 6
        main(args, num_classes)
    else:
        # å‘½ä»¤è¡Œæ¨¡å¼
        parser = argparse.ArgumentParser(description='EfficientNet Classification')
        parser.add_argument('--data', metavar='DIR',
                            default='/kaggle/input/your-dataset/data',
                            help='path to dataset')
        parser.add_argument('--epochs', default=50, type=int, help='number of total epochs to run')
        parser.add_argument('--batch-size', default=16, type=int, help='batch size')
        parser.add_argument('--lr', default=0.0005, type=float, help='initial learning rate')
        parser.add_argument('--workers', default=4, type=int, help='number of data loading workers')
        parser.add_argument('--image_size', default=224, type=int, help='image size')
        parser.add_argument('--device', default='cuda' if torch.cuda.is_available() else 'cpu',
                            help='device to use for training')
        parser.add_argument('--num_heads', default=8, type=int, help='number of attention heads')
        parser.add_argument('--reduction', default=10, type=int, help='channel reduction ratio for RP-aware gates')

        num_classes = 6  # è¿™é‡Œè®¾ç½®åˆ†ç±»çš„ç±»åˆ«

        args = parser.parse_args()
        main(args, num_classes)

